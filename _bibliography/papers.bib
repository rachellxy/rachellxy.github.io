---
---

@article{cai2025timeseriesgym,
  abbr={arXiv},
  title={TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents},
  author={Cai*, Yifu and Li*, Xinyu and Goswami*, Mononito and Wili{\'n}ski*, Micha{\l} and Welter, Gus and Dubrawski, Artur},
  note = {*Equal contribution},
  abstract={We introduce TimeSeriesGym, a scalable benchmarking framework for evaluating Artificial Intelligence (AI) agents on time series machine learning engineering challenges. Existing benchmarks lack scalability, focus narrowly on model building in well-defined settings, and evaluate only a limited set of research artifacts (e.g., CSV submission files). To make AI agent benchmarking more relevant to the practice of machine learning engineering, our framework scales along two critical dimensions. First, recognizing that effective ML engineering requires a range of diverse skills, TimeSeriesGym incorporates challenges from diverse sources spanning multiple domains and tasks. We design challenges to evaluate both isolated capabilities (including data handling, understanding research repositories, and code translation) and their combinations, and rather than addressing each challenge independently, we develop tools that support designing multiple challenges at scale. Second, we implement evaluation mechanisms for multiple research artifacts, including submission files, code, and models, using both precise numeric measures and more flexible LLM-based evaluation approaches. This dual strategy balances objective assessment with contextual judgment. Although our initial focus is on time series applications, our framework can be readily extended to other data modalities, broadly enhancing the comprehensiveness and practical utility of agentic AI evaluation. We open-source our benchmarking framework to facilitate future research on the ML engineering capabilities of AI agents.},
  journal={arXiv preprint arXiv:2505.13291},
  year={2025},
  html={https://arxiv.org/abs/2505.13291},
  code={https://github.com/moment-timeseries-foundation-model/TimeSeriesGym},
  selected={true},
}

@article{li2024personalized,
  abbr={arXiv},
  title={Personalized language modeling from personalized human feedback},
  author={Li, Xinyu and Zhou, Ruiyang and Lipton, Zachary C and Leqi, Liu},
  abstract={Personalized large language models (LLMs) are designed to tailor responses to individual user preferences. While Reinforcement Learning from Human Feedback (RLHF) is a commonly used framework for aligning LLMs with human preferences, vanilla RLHF assumes that all human preferences share the same distribution, preventing fine-tuned LLMs from generating personalized content when user preferences are diverse. In this work, we propose Personalized-RLHF (P-RLHF), an efficient framework that utilizes a lightweight user model to capture individual user preferences and jointly learns the user model and the personalized LLM from human feedback. P-RLHF exhibits the following three characteristics: (1) It enables an LLM to generate personalized content and scale efficiently with growing number of users. (2) It handles both explicit user preferences described as textual input and implicit user preferences encoded in the feedback data. (3) It eliminates the need for users to fully articulate their preferences, which are normally needed for prompting LLMs to generate personalized content yet are often impractical to obtain in real-world scenarios. Our experimental results show that personalized LLMs trained using P-RLHF generate responses that are more closely aligned with individual user preferences, outperforming vanilla, non-personalized RLHF and prompting-based personalization approaches across different tasks. We opensource our code at https://github.com/HumainLab/Personalized_RLHF.},
  journal={NeurIPS 2024 Workshop on Adaptive Foundation Models},
  year={2024},
  html={https://arxiv.org/abs/2402.05133},
  code={https://github.com/HumainLab/Personalized_RLHF},
  selected={true},
}

@inproceedings{schuerkamp2024adapting,
  abbr={AAAI},
  title={Adapting Animal Models to Assess Sufficiency of Fluid Resuscitation in Humans (Student Abstract)},
  author={Schuerkamp, Ryan and Li, Xinyu and Kunzer, Brian and Weiss, Leonard S and G{\'o}mez, Hernando and Guyette, Francis X and Pinsky, Michael R and Dubrawski, Artur},
  abstract={Fluid resuscitation is an initial treatment frequently employed to treat shock, restore lost blood, protect tissues from injury, and prevent organ dysfunction in critically ill patients. However, it is not without risk (e.g., overly aggressive resuscitation may cause organ damage and even death). We leverage machine learning models trained to assess sufficiency of resuscitation in laboratory animals subjected to induced hemorrhage and transfer them to use with human trauma patients. Our key takeaway is that animal experiments and models can inform human healthcare, especially when human data is limited or when collecting relevant human data via potentially harmful protocols is unfeasible.},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={21},
  pages={23644--23646},
  year={2024},
  html={https://ojs.aaai.org/index.php/AAAI/article/view/30508},
  selected={false},
}

@article{li2022automated,
  abbr={Sensors},
  title={Automated Assessment of Cardiovascular Sufficiency Using Non-Invasive Physiological Data},
  author={Li, Xinyu and Pinsky, Michael R and Dubrawski, Artur},
  abstract={For fluid resuscitation of critically ill individuals to be effective, it must be well calibrated in terms of timing and dosages of treatments. In current practice, the cardiovascular sufficiency of patients during fluid resuscitation is determined using primarily invasively measured vital signs, including Arterial Pressure and Mixed Venous Oxygen Saturation (SvO2), which may not be available in outside-of-hospital settings, particularly in the field when treating subjects injured in traffic accidents or wounded in combat where only non-invasive monitoring is available to drive care. In this paper, we propose (1) a Machine Learning (ML) approach to estimate the sufficiency utilizing features extracted from non-invasive vital signs and (2) a novel framework to address the detrimental impact of inter-patient diversity on the ability of ML models to generalize well to unseen subjects. Through comprehensive evaluation on the physiological data collected in laboratory animal experiments, we demonstrate that the proposed approaches can achieve competitive performance on new patients using only non-invasive measurements. These characteristics enable effective monitoring of fluid resuscitation in real-world acute settings with limited monitoring resources and can help facilitate broader adoption of ML in this important subfield of healthcare.},
  journal={Sensors},
  volume={22},
  number={3},
  pages={1024},
  year={2022},
  publisher={MDPI},
  html={https://www.mdpi.com/1424-8220/22/3/1024},
  selected={true},
}

@article{nagpal2021deep,
  abbr={IEEE JBHI},
  title={Deep survival machines: Fully parametric survival regression and representation learning for censored data with competing risks},
  author={Nagpal, Chirag and Li, Xinyu and Dubrawski, Artur},
  abstract={We describe a new approach to estimating relative risks in time-to-event prediction problems with censored data in a fully parametric manner. Our approach does not require making strong assumptions of constant proportional hazards of the underlying survival distribution, as required by the Cox-proportional hazard model. By jointly learning deep nonlinear representations of the input covariates, we demonstrate the benefits of our approach when used to estimate survival risks through extensive experimentation on multiple real world datasets with different levels of censoring. We further demonstrate advantages of our model in the competing risks scenario. To the best of our knowledge, this is the first work involving fully parametric estimation of survival times with competing risks in the presence of censoring.},
  journal={IEEE Journal of Biomedical and Health Informatics},
  volume={25},
  number={8},
  pages={3163--3175},
  year={2021},
  publisher={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/9326348?casa_token=Ic0grGkDVtoAAAAA:8hOShCI1slbwyxtCUjBdyI9IOJ6PjGYc6MIawDe-axJ3FICCmfzh--tgWqt02hffDLrNOYFDLg},
  code={https://autonlab.org/auton-survival/},
  selected={true},
}

@inproceedings{nagpal2019dynamically,
  abbr={MLHC},
  title={Dynamically personalized detection of hemorrhage},
  author={Nagpal, Chirag and Li, Xinyu and Pinsky, Michael R and Dubrawski, Artur},
  abstract={Rapid detection of hemorrhage is of major interest to the critical care community, enabling clinicians to take swift actions to mitigate adverse outcomes. In this paper, we describe a model that allows rapid detection of the onset of hemorrhage by monitoring the Central Venous Pressure (CVP). As opposed to prior work in the domain, our model does not rely on prior availability of a stable physiology of a patient as a baseline of reference, and it makes generative assumptions on the monitored vital sign. This allows for rapid on-the-fly personalization to a previously unseen patientâ€™s physiology. This property makes the proposed approach particularly relevant to e.g. trauma care and other scenarios where reference hemodynamic data may not be readily available for any new patient. We compare our model against strong discriminative alternatives and demonstrate its potential utility through empirical evaluation.},
  booktitle={Machine Learning for Healthcare Conference},
  pages={109--123},
  year={2019},
  organization={PMLR},
  html={https://proceedings.mlr.press/v106/nagpal19a},
  selected={true},
}

@article{li2018leveraging,
  abbr={ML4H},
  title={Leveraging Routine Pre-Operative Blood Draws to Predict Hemorrhagic Shock During Surgery},
  author={Li, Xinyu and Pinsky, Michael R and Clermont, Gilles and Dubrawski, Artur},
  abstract={We investigate the utility of machine learning to estimate the likelihood of surgical patients to develop a hemorrhagic shock during surgery. We use hemodynamic responses to routine blood draws as virtual indicators of future shock. Our results suggest that by capturing sequential patterns in vital signs waveform data observed in pre-surgical settings, it is possible to predict which patients will likely get into shock in the course of surgery. These findings, after further validation, can enable building clinically useful screening tools to preempt complications in surgical patients and to inform medical resource allocation and planning, with the use of only already performed diagnostic procedures: routine lab test blood draws.},
  journal={NeurIPS Machine Learning for Health (ML4H) Workshop},
  year={2018},
  pdf={ML4H2018_paper_XinyuLi.pdf},
  selected={false},
}
